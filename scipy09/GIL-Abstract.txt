Understanding GIL and How it affects your processing speed.
===========================================================

O.R. Senthil Kumaran
---------------------

Abstract
========

The Global Interpretor Lock serializes access to most parts of the interpreter.
The design of the Global Interpretor lock is such that it hands over the task
of thread scheduling to the operating system, it is a perfect design when it
comes to Operating Systems running on a single core processor but not with
multicore processors.  With the in burst of the multi core processors, Python
has been facing serious challenges in terms of utilizing the full power of
multi-core systems.  The reason often cited is the well known, and perhaps not
properly well-understood, acronym GIL. 

The reason it is not really well understood is that the topic of GIL falls
under Operating Systems and Scheduling than it is a Python Programming problem
or a programming paradigm. 

This talk will try to dive a little bit into Operating System process handling,
threading and thread scheduling till we understand the need of
synchronization and its problems and attempts to solve the Synchronization
issues. Next we will deal with the design of the GIL. This will explain in
detail, with execution examples the properties and the oddities of GIL.  A
measurement of the processing time of threaded different threaded programs and
its behavior on single core processor and multi-core processors would help us
understand the problem.

Python core developer, Antoine Pitrou led to solve some of the GIL imposed
deficiencies of Python Interpretor and came with a design that addresses the
issues of switching by opcode counts and thread switching latency. Let us look
at some of the changes made by him.

He also provides a good test suite, which has simple programs like calculating
pi, regex search, sorting and compress/decompress operations and provides a
timed framework to execute those operations on a controlled way by specifying
the number of threads and thread switching interval time. We shall look at the
performance measurement of concurrency benchmark tool when executed on a newgil
based Python interpretor.

More points
-----------

Global Interpreter Lock
=======================

 Currently, The Python Interpreter (Python 2.3.4) is not thread safe. There are
no priorities, no thread groups. Threads cannot be stopped and suspended,
resumed or interrupted. That is, the support provided is very much basic.
However a lot can still be accomplished with this meager support, with the use
of the threading module, as we shall see in the following sections. One of the
main reasons is that in actuality only one thread is running at a time. This is
because of some thing called a Global Interpreter Lock (GIL). In order to
support multi-threaded Python programs, there's a global lock that must be held
by the current thread before it can safely access Python objects. Without the
lock competing threads could cause havoc, for example: when two threads
simultaneously increment the reference count of the same object, the reference
count could end up being incremented only once instead of twice. Thus only the
thread that has acquired the GIL may operate on Python Objects or call Python C
API functions.

In order to support multi threaded Python programs the interpreter regularly
releases and reacquires the lock, by default every 10 bytecode instructions.
This can however be changed using the sys.setcheckinterval() function. The lock
is also released and reacquired around potentially blocking I/O operations like
reading or writing a file, so that other threads can run while the thread that
requests the I/O is waiting for the I/O operation to complete.

In particular note:

    * C extensions can release the GIL.
    * Blocking I/O can release the GIL.

The Python Interpreter keeps some book keeping info per thread, for which it
uses a data structure called PyThreadState. Earlier the state was stored in
global variables and switching threads could cause problems. In particular,
exception handling is now thread safe when the application uses sys.exc_info()
to access the exception last raised in the current thread. There's one global
variable left, however: the pointer to the current PyThreadState structure.
While most thread packages have a way to store ``per-thread global data,''
Python's internal platform independent thread abstraction doesn't support this
yet. Therefore, the current thread state must be manipulated explicitly. The
global interpreter lock is used to protect the pointer to the current thread
state. When releasing the lock and saving the thread state, the current thread
state pointer must be retrieved before the lock is released (since another
thread could immediately acquire the lock and store its own thread state in the
global variable). Conversely, when acquiring the lock and restoring the thread
state, the lock must be acquired before storing the thread state pointer


Python threading
================

A single interpreter runs in a single process. Within that process,
only one thread can be interpreting Python byte codes at one time. If
a thread is blocked, for example waiting for I/O, another thread can
run. Some C extensions release the GIL so other threads can run
concurrently.


sys.setcheckinterval(interval)

    Set the interpreter’s “check interval”. This integer value determines how
often the interpreter checks for periodic things such as thread switches and
signal handlers. The default is 100, meaning the check is performed every 100
Python virtual instructions. Setting it to a larger value may increase
performance for programs using threads. Setting it to a value <= 0 checks every
virtual instruction, maximizing responsiveness as well as overhead.

"Is there a python implementation that can run multiple compute-bound processes
on multiple cores concurrently."

- the multiprocessing module in the std lib - here is an example of
using it with numpy:

http://folk.uio.no/sturlamo/python/multiprocessing-tutorial.pdf

- Jython and IronPython both have threading models that allow multiple
threads to run concurrently on multiple processors.


Cannot we get rid to GIL
========================

3.5   Can't we get rid of the Global Interpreter Lock?

The Global Interpreter Lock (GIL) is often seen as a hindrance to Python's
deployment on high-end multiprocessor server machines, because a multi-threaded
Python program effectively only uses one CPU, due to the insistence that
(almost) all Python code can only run while the GIL is held.

Back in the days of Python 1.5, Greg Stein actually implemented a comprehensive
patch set (the "free threading" patches) that removed the GIL and replaced it
with fine-grained locking. Unfortunately, even on Windows (where locks are very
efficient) this ran ordinary Python code about twice as slow as the interpreter
using the GIL. On Linux the performance loss was even worse because pthread
locks aren't as efficient.

Since then, the idea of getting rid of the GIL has occasionally come up but
nobody has found a way to deal with the expected slowdown, and users who don't
use threads would not be happy if their code ran at half at the speed. Greg's
free threading patch set has not been kept up-to-date for later Python
versions.

This doesn't mean that you can't make good use of Python on multi-CPU machines!
You just have to be creative with dividing the work up between multiple
processes rather than multiple threads. Judicious use of C extensions will also
help; if you use a C extension to perform a time-consuming task, the extension
can release the GIL while the thread of execution is in the C code and allow
other threads to get some work done.

It has been suggested that the GIL should be a per-interpreter-state lock
rather than truly global; interpreters then wouldn't be able to share objects.
Unfortunately, this isn't likely to happen either. It would be a tremendous
amount of work, because many object implementations currently have global
state. For example, small integers and short strings are cached; these caches
would have to be moved to the interpreter state. Other object types have their
own free list; these free lists would have to be moved to the interpreter
state. And so on.

And I doubt that it can even be done in finite time, because the same problem
exists for 3rd party extensions. It is likely that 3rd party extensions are
being written at a faster rate than you can convert them to store all their
global state in the interpreter state.

And finally, once you have multiple interpreters not sharing any state, what
have you gained over running each interpreter in a separate process?

References:
===========

1. Inside the Python GIL
http://www.dabeaz.com/python/GIL.pdf

2. newgil
http://svn.python.org/view/sandbox/trunk/newgil/

3. newgil announcement
http://mail.python.org/pipermail/python-dev/2009-October/093321.html

4. Concurrency benchmark testsuite
http://svn.python.org/view/sandbox/trunk/ccbench/


Notes to Reviewers
==================

I have not used scientific python related software much, but this topic
(newgil) I believe would be of interest to numpy package and ofcourse other
scientific python tools.


About the Speaker
=================

I am a Python Core Developer and the maintainer of a urllib python standard
library module. Most of my work is around the standard library and internet
related modules. More recently, I got interested into Algorithms and Operating
Systems related areas and this topic of GIL interested me a lot.

I am Senior Software Engineer at Akamai Technologies, where we use Python and
twisted for a concurrent request handling server, amongst various other
tasks. 

I volunteer for Spastics Society of Karnataka and also interested in
accessibility technologies.


Past Speaking Experiences
=========================

1. Tutorial on Python Standard Library - PyCon US 2009.
2. Algorithms in Python - PyCon India 2009.
3. Python Stadard Library (Freed.in 2007), Pygame (Freed.in 2009)
4. Scheduled tutorial ( Solve it using Python - PyCon US 2010).
